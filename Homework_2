import org.apache.spark.util.StatCounter
import org.apache.spark.rdd.RDD
case class MatchData(id1: Int, id2: Int, scores: Array[Double], matched: Boolean)

val rawblocks = sc.textFile("block_1.csv")
def isHeader(line: String):Boolean={line.contains("id_1")}
val noheader = rawblocks.filter(x => !isHeader(x))
val first = noheader.take(1)
val line = first(0)
val pieces = line.split(',')
val id1 = pieces(0).toInt
val id2 = pieces(1).toInt

def toDouble(s: String) = {
if("?".equals(s)||"".equals(s)) Double.NaN else s.toDouble
}

def toBoolean(s: String) = {
if("".equals(s)) false else s.toBoolean
}

def toInt(s: String) = {
if("?".equals(s)||"".equals(s)) 0 else s.toInt
}

def parse(line: String) = {
val pieces = line.split(',')
val id1 = pieces(0).toInt
val id2 = pieces(1).toInt
val scores = pieces.slice(2,11).map(toDouble)
val matched = pieces(11).toBoolean
MatchData(id1, id2, scores, matched)
}


val parsed = noheader.map(line => parse(line)) //question 4



class NAStatCounter extends Serializable{
val stats: StatCounter = new StatCounter()
var missing: Long = 0
def add(x: Double): NAStatCounter = {
if(java.lang.Double.isNaN(x)){
missing+=1
} else{
stats.merge(x)
}
this
}
def merge (other: NAStatCounter): NAStatCounter = {
stats.merge(other.stats)
missing += other.missing
this
}
override def toString = {
"stats: " + stats.toString + "NaN: " + missing
}
}

object NAStatCounter extends Serializable{
def apply(x: Double) = new NAStatCounter().add(x)
}


def statsWithMissing(rdd: RDD[Array[Double]]): Array[NAStatCounter] = {
val nastats = rdd.mapPartitions((iter: Iterator[Array[Double]]) => {
if(iter.hasNext){
val nas: Array[NAStatCounter] = iter.next().map(d => NAStatCounter(d))
iter.foreach(arr => {
nas.zip(arr).foreach { case (n, d) => n.add(d) }
})
Iterator(nas)
} else {
Iterator.empty}})
nastats.reduce((n1, n2) => {
n1.zip(n2).map { case (a, b) => a.merge(b) }
})
}


val statsm = statsWithMissing(parsed.filter(_.matched).map(_.scores)) 
val statsn = statsWithMissing(parsed.filter(!_.matched).map(_.scores))
statsm.zip(statsn).map { case(m, n) =>(m.missing + n.missing, m.stats.mean - n.stats.mean) }.foreach(println)


//I am unsure as to why statsm is not running correctly, but since it is not, these numbers are not totally correct. I've gone ahead and calculated the best features with the numbers I do have.

/*(202,0.0010378828680847052)	//q = 5.3326E-9
(1127211,0.0012273669565108225) //
(0,0.002491882484452701)
(1147308,0.1804428236116048)
(0,1.2567951775277475E-4)
(124,0.002815476102533687)
(124,0.0018599207052170108)
(124,0.002826602569765302)
(2586,0.0034688022087556655)*/
